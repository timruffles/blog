title: Penrose
draft: true
body: |
  Programming languages don't exist. The idea of function application has absolutely nothing to do with 1s and 0s, but everything to do with mathematics. We translate the language of mathematics into a series of lower languages, together forming a system that behaves as the language dictates.

  For instance, a 'function' or 'array' felt very basic to me. The idea of applying operations to operands felt like raw computer stuff when I began programming.

  But when I read SICP and saw operator application being carried out via an interpreter, turning list(+ 1 1) into the behaviour we expect by shifting the + out, finding the operation (speficified in the lower level language) it represented and applying it to the evaluated values of 1 and 1 in that lower level language, to exhibit the behaviour the higher level languages dictated, but in a process in which that higher level language was translted away, it finally clicked.

  This has fascinating implications. Searle's chinese room is a system as follows:

  Text + Question about it in, both in Chinese -> Room containing Searle and a machine that manipulates Chinese characters, with instructions in input = correct answers to question in Chinese, although Searle doesn't understand Chinese.

  Searle points out the answers are correct although he doesn't understand Chinese, and makes this an argument against a computer which also performs this function doing so.

  However, the /system/ does! Searle is working on the wrong level, bifurcating what should be whole into 'me' and the 'machine'. He + machine = understands Chinese. 

  The parrallel to conciousness is made more clear when Searle is replaced by numerous other people, say the population of India. The parallel to the human brain of a Chinese person, whose individual neurons do not understand Chinese, but the system - the brain - does, is clearer.

  What it comes down to is that languages can be translated down into lower level system that behave as if the (imaginary) language was carried out. 

  The language of the human brain works on a high level, and is translated down into chemicals and neurons. If we refigured these into an algorithm, we could feed that into any Turing complete machine, whether constructed of electrical circuits (or perhaps an interpreted language built on an interpreted language...), or ants nests, or water wheels, and the system would behave as if it were concious.

  But what is the difference between a series of biological circuits behaving as if they were concious and our mechanical/electronic/hydraulic contraption?

  To take another example, how can you tell people feel pain the same way you do? You can poke them, to see if they yelp like you. But you want to see if they have the same stuff going on in their mind as you, so you hook them up to an brain scanner and see that the patterns are inditical. They are! But is the same indefinable 'stuff' going on for them as it is for you? The alarming OWWW clanging into your conciousness? 

  In fact, there is no empirical test you could carry out with a positive result on a human, that could not also be carried out on a machine. For instance, if you wired up an electronic circuit of the same logical complexity as the human brain, and scanned it while being subjected to the same pain inputs, what if it /looked/ the same as your brain scan being so subjected?

  We fall back to deductive logic. Humans feel pain in way X, computers are not human, therefore they cannot feel pain in way X. Two problems, firstly this is based (as is all deduction) on induction, namely: I am a human, I feel pain in way X. If we genearlise this experience, the deductive law is suggested: humans feel pain in way X. Secondly, we would have to determine tests to prove (or to even suggest there is a case to be made for) that since computers aren't human, they don't feel pain in the same way. That test would be based on the behaviour the system displayed! and, as discussed above, that test would be positive. 

  The language of conciousness can be translated... The really hard part is asking what this means. Does conciousness get generated by systems? Are all systems thus concious, but to a lesser degree? Are we really the process of a logical system? Is an ant's nest, whoes logic is executed by millions of effectively mindless ants, as able to perceive the colony language as we are ours?